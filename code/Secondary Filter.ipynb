{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e208ba74",
   "metadata": {},
   "source": [
    "# 第二層過濾\n",
    "使用 Bidirectional LSTM 模型進行判斷"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23759979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3df68252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop words OK.\n"
     ]
    }
   ],
   "source": [
    "# stop words\n",
    "stopwords_file = open(\"../stop_words.txt\", \"r\")\n",
    "stopwords = stopwords_file.readlines()\n",
    "stopwords = [item.strip(\"\\n\") for item in stopwords]\n",
    "print(\"stop words OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8b44463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/hsiaoping.zhang/Desktop/AIDEA/dict.txt.big ...\n",
      "Loading model from cache /var/folders/rd/0nr5tzsn2z17vy9fjcj5rlsc0000gn/T/jieba.u5524b13f3f9f1a3fca714e7a1c7506b3.cache\n",
      "Loading model cost 0.509 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary loaded OK.\n"
     ]
    }
   ],
   "source": [
    "# dictionary\n",
    "import jieba\n",
    "\n",
    "jieba.set_dictionary('../dict.txt.big')\n",
    "jieba.load_userdict('../chem_dict.txt')\n",
    "jieba.load_userdict('../crop_dict.txt')\n",
    "jieba.load_userdict('../pest_dict.txt')\n",
    "\n",
    "print(\"dictionary loaded OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa4004d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_crop(fileNum):\n",
    "    rows = get_file_rows(fileNum)\n",
    "    item = rows[0].strip(\"\\n\").split(\",\")[0]\n",
    "    row2 = [] if rows[1] == \"\\n\" else rows[1].strip(\"\\n\").split(\",\")\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd384724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_rows(fileNum):\n",
    "    file = open(f\"../{currentFolder}/data/{fileNum}.csv\", \"r\")\n",
    "    rows = file.readlines()\n",
    "    file.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217f8af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFolder = \"train\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46a7369",
   "metadata": {},
   "source": [
    "### 先讀入帶有標籤(label)的檔案當作 training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d4a2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_label_file(path):\n",
    "    file = open(path, \"r\")\n",
    "    result = file.readlines()[1:]\n",
    "    result = [item.strip(\"\\n\") for item in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49bf09aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['747,673,0', '381,747,0', '381,351,0', '381,673,0', '351,747,1'], 5918)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train label: 從第一層過濾得來的組合結果\n",
    "ans = read_label_file(\"../train/lstm-train-label.csv\")\n",
    "ans[:5], len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6037dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['747, 673, 0', '381, 747, 0', '381, 351, 0', '381, 673, 0', '351, 747, 1'],\n",
       " 5906)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test data: 過濾 label 為 related 和 unrelated 的比例為 1:1\n",
    "test = read_label_file(\"../train/re-train.csv\")\n",
    "test_input = test.copy()\n",
    "test[:5], len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8185531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['683, 641', '639, 657', '639, 708', '402, 683', '551, 948'], 1823)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# public label\n",
    "file = open(\"../private/submission/1214_0443.csv\", \"r\")\n",
    "public = file.readlines()[1:]\n",
    "public = [item.strip(\"\\n\") for item in public]\n",
    "public[:5], len(public)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0037739",
   "metadata": {},
   "source": [
    "### 正式讀入各文章的斷詞結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f2e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee89a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀檔\n",
    "def get_article_segment(fileNum):\n",
    "    file = open(f\"../{currentFolder}/TF-IDF/{fileNum}.txt\", \"r\")\n",
    "    sentances = file.readlines()[0].strip(\"\\n\")\n",
    "    \n",
    "    return sentances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40eeb87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_to_df(label_list, is_label):\n",
    "    sentance1, sentance2, label = [], [], []\n",
    "    \n",
    "    # 兩兩文章組合各自讀檔\n",
    "    for itemString in label_list:\n",
    "        items = itemString.split(\",\")\n",
    "        item1, item2 = int(items[0]), int(items[1])\n",
    "        sentance1.append(get_article_segment(item1))\n",
    "        sentance2.append(get_article_segment(item2))\n",
    "        if(is_label):\n",
    "            label.append(int(items[2]))\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df[\"sentance_1\"] = sentance1\n",
    "    df[\"sentance_2\"] = sentance2\n",
    "    \n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e1abe039",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentance_1</th>\n",
       "      <th>sentance_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...</td>\n",
       "      <td>柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...</td>\n",
       "      <td>柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...</td>\n",
       "      <td>柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...</td>\n",
       "      <td>柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...</td>\n",
       "      <td>柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentance_1  \\\n",
       "0  柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...   \n",
       "1  柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...   \n",
       "2  柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...   \n",
       "3  柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...   \n",
       "4  柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...   \n",
       "\n",
       "                                          sentance_2  label  \n",
       "0  柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...      0  \n",
       "1  柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...      0  \n",
       "2  柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...      0  \n",
       "3  柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...      0  \n",
       "4  柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...      1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先把文章前 100 字 load 進 df 當中\n",
    "print(\"...\")\n",
    "currentFolder = \"train\"\n",
    "df, train_label = load_to_df(ans, True)\n",
    "df[\"label\"] = train_label\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "be9605d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期 蚜蟲 潛葉蛾 薊馬 確保 柑橘 品質 南區 確保 品質 蚜蟲 柑橘 吸取 時會 新芽 生長 誘發 潛葉蛾 柑橘 生長 時期 幼蟲 孵化 潛入 嫩葉 組織 葉肉 被害 停止 生育 枝條 發育 柑橘類 薊馬 小黃薊馬 花薊馬 新芽 生長期 開花期 幼果 此類 害蟲 體型 細小 習性 新芽 生長期 受害 皺縮 生長 開花期 薊馬 群集 花器 取食 花器 受害 授粉 幼果 薊馬 刺吸式 口器 柑橘 幼果 表皮 細胞 吸取 汁液 果皮 粗糙 不規則 發現 受害 最佳 時機 薊馬 潛葉蛾 把握 新芽 開花 小果 最佳 時機 確保 柑橘 品質 薊馬 繁殖 速度 初期 事半功倍 小黃薊馬 丁基加保扶乳劑 柑橘 潛葉蛾 種類 芬諾克可濕性粉劑 陶斯松 濕性 粉劑 佈飛賽滅寧乳劑 蚜蟲 免扶克乳劑 大滅松乳劑 福賜米松溶液 參考 植物保護 手冊 用藥 本場 植保 研究室 人員 '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0][\"sentance_1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8693f32d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentance_1</th>\n",
       "      <th>sentance_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...</td>\n",
       "      <td>柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...</td>\n",
       "      <td>柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...</td>\n",
       "      <td>柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...</td>\n",
       "      <td>柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...</td>\n",
       "      <td>柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentance_1  \\\n",
       "0  柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...   \n",
       "1  柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...   \n",
       "2  柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...   \n",
       "3  柑橘類 花期 農民 小型 害蟲 臺南 改場 防檢局 田邊 好幫手 關心 柑橘類 水果 種類 ...   \n",
       "4  柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...   \n",
       "\n",
       "                                          sentance_2  label  \n",
       "0  柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...      0  \n",
       "1  柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...      0  \n",
       "2  柑橘類 盛花期 臺南 蚜蟲 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 盛花期 蚜蟲 ...      0  \n",
       "3  柑橘類 陸續 開花期 蚜蟲 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 ...      0  \n",
       "4  柑橘類 開花期 蚜蟲 潛葉蛾 薊馬 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 生長 開花期...      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"...\")\n",
    "df2, test_label = load_to_df(test, True)\n",
    "df2[\"label\"] = test_label\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ea996d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentance_1</th>\n",
       "      <th>sentance_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>柑桔窄胸天牛 羽化 柑桔窄胸天牛 羽化 工作 應於 展開 南區 農業 改良場 確實 降低 柑...</td>\n",
       "      <td>柑桔窄胸天牛 幼蟲 孵化 盛期 南區 農業 改良場 籲請 把握 黃金 柑桔窄胸天牛 幼蟲 孵...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>柑桔 果實 幼果 台南 改場 薊馬 確保 果實 品質 柑桔 果實 幼果 台南 改場 薊馬 確...</td>\n",
       "      <td>柑橘類 開花 時期 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 茂...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>柑桔 果實 幼果 台南 改場 薊馬 確保 果實 品質 柑桔 果實 幼果 台南 改場 薊馬 確...</td>\n",
       "      <td>小黃薊馬 密度 台南 改場 確保 果實 品質 南區 水果 芒果 文旦 幼果 果實 小黃薊馬 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>柑橘窄胸天牛 羽化 籲請 把握 關鍵 時機 臺南 改場 防檢局 田邊 好幫手 關心 柑橘窄胸...</td>\n",
       "      <td>柑桔窄胸天牛 羽化 柑桔窄胸天牛 羽化 工作 應於 展開 南區 農業 改良場 確實 降低 柑...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>台東 水稻 徒長病 新聞稿 本田 拔除 水稻 徒長病 減少 本縣 池上 鄉鎮 水稻 徒長病 ...</td>\n",
       "      <td>水稻 秧苗 病蟲害 管理 新聞稿 北部 地區 一期稻作 育苗 本田 初期 氣候 多變 濕度 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          sentance_1  \\\n",
       "0  柑桔窄胸天牛 羽化 柑桔窄胸天牛 羽化 工作 應於 展開 南區 農業 改良場 確實 降低 柑...   \n",
       "1  柑桔 果實 幼果 台南 改場 薊馬 確保 果實 品質 柑桔 果實 幼果 台南 改場 薊馬 確...   \n",
       "2  柑桔 果實 幼果 台南 改場 薊馬 確保 果實 品質 柑桔 果實 幼果 台南 改場 薊馬 確...   \n",
       "3  柑橘窄胸天牛 羽化 籲請 把握 關鍵 時機 臺南 改場 防檢局 田邊 好幫手 關心 柑橘窄胸...   \n",
       "4  台東 水稻 徒長病 新聞稿 本田 拔除 水稻 徒長病 減少 本縣 池上 鄉鎮 水稻 徒長病 ...   \n",
       "\n",
       "                                          sentance_2  \n",
       "0  柑桔窄胸天牛 幼蟲 孵化 盛期 南區 農業 改良場 籲請 把握 黃金 柑桔窄胸天牛 幼蟲 孵...  \n",
       "1  柑橘類 開花 時期 薊馬 潛葉蛾 確保 品質 柑橘類 水果 種類 文旦 白柚 椪柑 柳丁 茂...  \n",
       "2  小黃薊馬 密度 台南 改場 確保 果實 品質 南區 水果 芒果 文旦 幼果 果實 小黃薊馬 ...  \n",
       "3  柑桔窄胸天牛 羽化 柑桔窄胸天牛 羽化 工作 應於 展開 南區 農業 改良場 確實 降低 柑...  \n",
       "4  水稻 秧苗 病蟲害 管理 新聞稿 北部 地區 一期稻作 育苗 本田 初期 氣候 多變 濕度 ...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "currentFolder = \"private\"\n",
    "\n",
    "print(\"...\")\n",
    "df3, _ = load_to_df(public, False)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1661e249",
   "metadata": {},
   "source": [
    "### 使用 tensorflow\n",
    "將輸入的字詞們轉成模型能夠接受的型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48a1c1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 15000\n",
    "MAX_SEQUENCE_LENGTH = 100  # 一個標題最長有幾個詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35076408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11836,)\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "\n",
    "corpus_x1 = df[\"sentance_1\"]\n",
    "corpus_x2 = df[\"sentance_2\"]\n",
    "corpus = pd.concat([corpus_x1, corpus_x2])\n",
    "print(corpus.shape)\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7261743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "q1_train = tokenizer.texts_to_sequences(corpus_x1)\n",
    "q2_train = tokenizer.texts_to_sequences(corpus_x2)\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30f3c51e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "[1029 1164   76  722 1521  665   76   50   36  241 1131  353  110  341\n",
      "   90   47  168  810  189  957  232  186   69 1164 1263  268  129  725\n",
      "   92 1307  881 1118 1164 1263   45  903   76  268  232  535  808  366\n",
      "  808   45  850  129  232 1221  830  665  129  267  642  867  508  258\n",
      " 1058  504   15   45 1272  106  232 1521  184 1164  367 1036 1272  106\n",
      "   39  665   38  232  228  598    7 1192  186 1023  665 1521  191 1705\n",
      "  515  289  167 1706  230 1618 1619 1762   16   11   13  159  171  305\n",
      "  375  120]\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "X_train_q1 = tokenizer.texts_to_sequences(df['sentance_1'].values.astype(str))\n",
    "X_train_q1 = tf.keras.preprocessing.sequence.pad_sequences(X_train_q1, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "X_train_q2 = tokenizer.texts_to_sequences(df['sentance_2'].values.astype(str))\n",
    "X_train_q2 = tf.keras.preprocessing.sequence.pad_sequences(X_train_q2, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "Y_train = df[\"label\"]\n",
    "\n",
    "print(len(df.iloc[0]['sentance_1'].split(\" \")))\n",
    "print(X_train_q1[0])\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "320a43af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "X_test_q1 = tokenizer.texts_to_sequences(df2['sentance_1'].values.astype(str))\n",
    "X_test_q1 = tf.keras.preprocessing.sequence.pad_sequences(X_test_q1, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "X_test_q2 = tokenizer.texts_to_sequences(df2['sentance_2'].values.astype(str))\n",
    "X_test_q2 = tf.keras.preprocessing.sequence.pad_sequences(X_test_q2, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "y_test = df2[\"label\"]\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3654c960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "X_public_q1 = tokenizer.texts_to_sequences(df3['sentance_1'].values.astype(str))\n",
    "X_public_q1 = tf.keras.preprocessing.sequence.pad_sequences(X_public_q1, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "X_public_q2 = tokenizer.texts_to_sequences(df3['sentance_2'].values.astype(str))\n",
    "X_public_q2 = tf.keras.preprocessing.sequence.pad_sequences(X_public_q2, maxlen = MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01fb17a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1029, 1164,   76,  722, 1521,  665,   76,   50,   36,  241, 1131,\n",
       "        353,  110,  341,   90,   47,  168,  810,  189,  957,  232,  186,\n",
       "         69, 1164, 1263,  268,  129,  725,   92, 1307,  881, 1118, 1164,\n",
       "       1263,   45,  903,   76,  268,  232,  535,  808,  366,  808,   45,\n",
       "        850,  129,  232, 1221,  830,  665,  129,  267,  642,  867,  508,\n",
       "        258, 1058,  504,   15,   45, 1272,  106,  232, 1521,  184, 1164,\n",
       "        367, 1036, 1272,  106,   39,  665,   38,  232,  228,  598,    7,\n",
       "       1192,  186, 1023,  665, 1521,  191, 1705,  515,  289,  167, 1706,\n",
       "        230, 1618, 1619, 1762,   16,   11,   13,  159,  171,  305,  375,\n",
       "        120], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_q1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aa5b4881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5918, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa942dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VALIDATION_RATIO = 0.2\n",
    "RANDOM_STATE = 9527\n",
    "\n",
    "x_train_q1, x_val_q1, \\\n",
    "x_train_q2, x_val_q2, \\\n",
    "y_train, y_val = \\\n",
    "    train_test_split(\n",
    "        X_train_q1, X_train_q2, Y_train, \n",
    "        test_size=VALIDATION_RATIO, \n",
    "        random_state=RANDOM_STATE\n",
    ")\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6615a864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "-\n",
      "[[0. 1.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 分兩類\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "print(y_train[:5])\n",
    "\n",
    "print(\"-\")\n",
    "\n",
    "y_val = tf.keras.utils.to_categorical(y_val)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "840dc73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EMBEDDING_DIM = 256  # 一個詞向量的維度\n",
    "NUM_LSTM_UNITS = 128     # LSTM 輸出的向量維度\n",
    "NUM_CLASSES = 2          # related / unrelated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3c2412d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "model = word2vec.Word2Vec.load(\"20180309-wiki-model/20180309wiki_model.bin\")\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562b118a",
   "metadata": {},
   "source": [
    "### embedding 層\n",
    "使用 word2vec 進行嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d63265ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "embedding_matrix = np.zeros((len(list(model.wv.index_to_key)) + 1, model.vector_size))\n",
    "word2idx = {}\n",
    "\n",
    "vocab_list = [(word, model.wv[word]) for word in list(model.wv.key_to_index.keys())]\n",
    "i = 0\n",
    "for vocab in enumerate(vocab_list):\n",
    "    word = vocab\n",
    "    word, vec = vocab_list[i][0], vocab_list[i][1]\n",
    "\n",
    "    embedding_matrix[i + 1] = vec\n",
    "    word2idx[word] = i + 1\n",
    "    i += 1\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5114f892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(771279, 250)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "82034492",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "# embedding_layer = layers.Embedding(MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "embedding_layer = layers.Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                            output_dim=embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6931f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6eaed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "# 建立孿生 LSTM 架構（Siamese LSTM）\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.layers import Embedding, LSTM, concatenate, Dense, Bidirectional, GRU, Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 分別定義 2 個文章 q1 & q2 為模型輸入兩個標題都是一個長度為 100 的數字序列\n",
    "q1_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "    dtype='int32')\n",
    "q2_input = Input(\n",
    "    shape=(MAX_SEQUENCE_LENGTH, ), \n",
    "    dtype='int32')\n",
    "\n",
    "\n",
    "# 詞嵌入層：經過詞嵌入層的轉換，兩個文章都變成一個詞向量的序列，而每個詞向量的維度為 256\n",
    "\n",
    "# 原本 keras 預設可支援的\n",
    "# embedding_layer = Embedding(MAX_NUM_WORDS, NUM_EMBEDDING_DIM)\n",
    "\n",
    "q1_embedded = embedding_layer(q1_input)\n",
    "q2_embedded = embedding_layer(q2_input)\n",
    "\n",
    "# LSTM 層：兩個文章經過此層後為一個 128 維度向量\n",
    "shared_lstm = Bidirectional(LSTM(NUM_LSTM_UNITS, dropout=0.1))\n",
    "\n",
    "q1_output = shared_lstm(q1_embedded)\n",
    "q2_output = shared_lstm(q2_embedded)\n",
    "\n",
    "\n",
    "# 串接層將兩個文章的結果串接單一向量方便跟全連結層相連\n",
    "merged = concatenate(\n",
    "    [q1_output, q2_output], \n",
    "    axis=-1)\n",
    "\n",
    "outer_dense = Dense(32, activation=\"relu\")\n",
    "\n",
    "# 全連接層搭配 Softmax Activation 可以回傳 2 個文章屬於各類別的可能機率\n",
    "dense =  Dense(\n",
    "    units=NUM_CLASSES, \n",
    "    activation='softmax')\n",
    "\n",
    "# predictions = dense(merged)\n",
    "predictions = dense(outer_dense(merged))\n",
    "\n",
    "# 模型就是將數字序列的輸入，轉換成 2 個分類的機率的所有步驟 / 層的總和\n",
    "model = Model(\n",
    "    inputs=[q1_input, q2_input], \n",
    "    outputs=predictions)\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60cb1a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Failed to import pydot. You must `pip install pydot` and install graphviz (https://graphviz.gitlab.io/download/), ', 'for `pydotprint` to work.')\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(\n",
    "    model, \n",
    "    to_file='model.png', \n",
    "    show_shapes=True, \n",
    "    show_layer_names=False, \n",
    "    rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "449ce4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 250)     192819750   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 256)          388096      embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           bidirectional[0][0]              \n",
      "                                                                 bidirectional[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            1026        concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 193,208,872\n",
      "Trainable params: 389,122\n",
      "Non-trainable params: 192,819,750\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "285f9c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6430aa73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5906, 100)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_q1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "829808b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2ba2bcf70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x2ba2bcf70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/48 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9154WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2ac6744c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x2ac6744c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "48/48 [==============================] - 42s 803ms/step - loss: 0.2273 - accuracy: 0.9153 - val_loss: 0.2706 - val_accuracy: 0.9105\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 38s 794ms/step - loss: 0.2048 - accuracy: 0.9259 - val_loss: 0.2840 - val_accuracy: 0.9029\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 38s 802ms/step - loss: 0.1995 - accuracy: 0.9304 - val_loss: 0.2818 - val_accuracy: 0.9071\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 39s 812ms/step - loss: 0.2083 - accuracy: 0.9270 - val_loss: 0.2833 - val_accuracy: 0.9088\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 38s 786ms/step - loss: 0.1993 - accuracy: 0.9294 - val_loss: 0.2828 - val_accuracy: 0.9088\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 37s 781ms/step - loss: 0.1907 - accuracy: 0.9285 - val_loss: 0.2832 - val_accuracy: 0.9003\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 37s 774ms/step - loss: 0.2010 - accuracy: 0.9248 - val_loss: 0.2783 - val_accuracy: 0.9079\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 38s 793ms/step - loss: 0.2011 - accuracy: 0.9260 - val_loss: 0.2840 - val_accuracy: 0.9071\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 38s 787ms/step - loss: 0.1943 - accuracy: 0.9292 - val_loss: 0.2844 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 38s 799ms/step - loss: 0.1753 - accuracy: 0.9368 - val_loss: 0.2891 - val_accuracy: 0.9037\n"
     ]
    }
   ],
   "source": [
    "# 決定一次要放多少成對標題給模型訓練\n",
    "BATCH_SIZE = 100  # 70 (for the best score)\n",
    "\n",
    "# 決定模型要看整個訓練資料集幾遍\n",
    "NUM_EPOCHS = 10  # 20 (for the best score)\n",
    "\n",
    "# 實際訓練模型\n",
    "history = model.fit(\n",
    "    # 輸入是兩個長度為 100 的數字序列\n",
    "    x=[x_train_q1, x_train_q2], \n",
    "    y=y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    # 每個 epoch 完後計算驗證資料集上的 Loss 以及準確度\n",
    "    validation_data=(\n",
    "        [x_val_q1, x_val_q2], \n",
    "        y_val\n",
    "    ),\n",
    "    # 每個 epoch 隨機調整訓練資料集裡頭的數據以讓訓練過程更穩定\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9999e8a",
   "metadata": {},
   "source": [
    "### Prediction for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5be65852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2ac4249d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x2ac4249d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.8459727e-01, 1.5402757e-02],\n",
       "       [9.9427468e-01, 5.7253367e-03],\n",
       "       [9.9985445e-01, 1.4554997e-04],\n",
       "       [9.7935426e-01, 2.0645689e-02],\n",
       "       [2.6339078e-02, 9.7366095e-01]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用已訓練的模型做預測\n",
    "test_predictions = model.predict(\n",
    "    [X_test_q1, X_test_q2])\n",
    "test_predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72807f6",
   "metadata": {},
   "source": [
    "### 查看結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47259801",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crop_list_index(name):\n",
    "    if(name == \"水稻\"):\n",
    "        return 0\n",
    "    elif(\"蕉\" in name):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af176227",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFolder = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ebe6a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess / answer: 0.7\n",
      "crop       | 00         | 01(unlike) | 10(like)   | 11        \n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
      "rice       | 3176       | 109        | 305        | 569       \n",
      "banana     | 509        | 33         | 177        | 395       \n",
      "others     | 474        | 4          | 58         | 97        \n",
      "precision: 0.66 | total guess: 1601 | right: 1061\n",
      "recall: 0.88 | total related: 1207\n",
      "socre: 0.7024164184045019 | recall: 0.7471830985915493\n",
      "total candidate: 5906\n"
     ]
    }
   ],
   "source": [
    "errors = [0 for i in range(3)]  # pred=1 ans=0\n",
    "losses = [0 for i in range(3)]  # pred=0 ans=1\n",
    "\n",
    "# prediction\n",
    "pred_true = [0 for i in range(3)]\n",
    "pred_false = [0 for i in range(3)]\n",
    "\n",
    "# answer\n",
    "ans_true = [0 for i in range(3)]\n",
    "ans_false = [0 for i in range(3)]\n",
    "\n",
    "# article number count\n",
    "crops = [0 for i in range(3)]\n",
    "\n",
    "true_11 = [0 for i in range(3)]\n",
    "true_00 = [0 for i in range(3)]\n",
    "\n",
    "no = 0\n",
    "threshold = 0.7\n",
    "count = 0\n",
    "\n",
    "\n",
    "for i in range(len(test_predictions)):\n",
    "    row = test_input[i].split(\",\")\n",
    "    item1, item2 = int(row[0]), int(row[1])\n",
    "    \n",
    "    crop = main_crop(item1)\n",
    "    index = get_crop_list_index(crop)\n",
    "    \n",
    "    # add to crop list\n",
    "    crops[index] += 1\n",
    "    \n",
    "    pred = test_predictions[i]\n",
    "    pred_label = 0 if(pred[0] > threshold) else 1\n",
    "    ans_label = df2.iloc[i][\"label\"]\n",
    "    \n",
    "    if(pred_label == 0 and ans_label == 1):\n",
    "        pred_false[index] += 1\n",
    "        ans_true[index] += 1\n",
    "        losses[index] += 1\n",
    "        # print(f\"unlike: [{item1}, {item2}]\", round(pred[0], 2))\n",
    "            \n",
    "    elif(pred_label == 1 and ans_label == 1):\n",
    "        pred_true[index] += 1\n",
    "        ans_true[index] += 1\n",
    "        true_11[index] += 1\n",
    "        # print(f\"true related: [{item1}, {item2}] {main_crop(item1)} -> {main_crop(item2)}\")\n",
    "\n",
    "    elif(pred_label == 1 and ans_label == 0):\n",
    "        pred_true[index] += 1\n",
    "        ans_false[index] += 1\n",
    "        errors[index] += 1\n",
    "        # print(f\"like: [{item1}, {item2}] {round(pred[0], 2)}\")\n",
    "        \n",
    "    else:\n",
    "        pred_false[index] += 1\n",
    "        ans_false[index] += 1\n",
    "        true_00[index] += 1\n",
    "        # print(f\"true unrelated: [{item1}, {item2}] {main_crop(item1)} -> {main_crop(item2)}\")\n",
    "\n",
    "\n",
    "right, total_guess, total_related = 0, 0, 0\n",
    "for i in range(3):\n",
    "    right += true_11[i]\n",
    "    total_guess += pred_true[i]\n",
    "    total_related += ans_true[i]\n",
    "    \n",
    "print(\"guess / answer:\", threshold)\n",
    "print(\"%-10s | %-10s | %-10s | %-10s | %-10s\" % (\"crop\", \"00\", \"01(unlike)\", \"10(like)\", \"11\"))\n",
    "print(\"- - - - - - - - - - - - - - - - - - - - - - - - - - - -\")\n",
    "names = [\"rice\", \"banana\", \"others\"]\n",
    "for i in range(3):\n",
    "    print(\"%-10s | %-10d | %-10d | %-10d | %-10d\" % (names[i], true_00[i], losses[i], errors[i], true_11[i]))\n",
    "    \n",
    "precision = right / total_guess\n",
    "recall = right / total_related\n",
    "base = 0.85  # 假設上一層的 recall 最多只能達到 0.85\n",
    "print(f\"precision: {round(precision, 2)} | total guess: {total_guess} | right: {right}\")\n",
    "print(f\"recall: {round(recall, 2)} | total related: {total_related}\")\n",
    "recall = recall * base\n",
    "print(f\"socre: {2*(precision * recall) / (precision + recall)} | recall: {recall}\")\n",
    "print(f\"total candidate: {len(test_input)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975b954",
   "metadata": {},
   "source": [
    "### Prediction for public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c44a0a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFolder = \"private\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5870bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.58139694, 0.41860312],\n",
       "       [0.993046  , 0.00695405],\n",
       "       [0.81041807, 0.18958198],\n",
       "       [0.9186404 , 0.08135963],\n",
       "       [0.8374131 , 0.16258694]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用已訓練的模型做預測\n",
    "predictions = model.predict(\n",
    "    [X_public_q1, X_public_q2])\n",
    "predictions[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd4390a",
   "metadata": {},
   "source": [
    "### 結果寫入檔案"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a99d37c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related: 609 | unrelated: 1214 | ratio: 0.10311547578733492\n",
      "1823\n"
     ]
    }
   ],
   "source": [
    "# write to file\n",
    "file = open(f\"../{currentFolder}/result.csv\", \"w\")\n",
    "file.write(\"Test,Reference\\n\")\n",
    "test, ref = [], []\n",
    "threshold = 0.7\n",
    "pred_true, pred_false = 0, 0\n",
    "\n",
    "\n",
    "for i in range(len(predictions)):\n",
    "    pred = predictions[i]\n",
    "    crop = main_crop(int(public[i].split(\",\")[0]))\n",
    "    \n",
    "    pred_label = 0 if(pred[0] > threshold) else 1\n",
    "    row = public[i].split(\",\")\n",
    "\n",
    "    item1, item2 = int(row[0]), int(row[1])\n",
    "    \n",
    "    if(pred_label == 1):\n",
    "        file.write(f\"{item1}, {item2}\\n\")\n",
    "        test.append(item1)\n",
    "        ref.append(item2)\n",
    "        pred_true += 1\n",
    "        \n",
    "    else:\n",
    "        pred_false += 1\n",
    "file.close()\n",
    "print(f\"related: {pred_true} | unrelated: {pred_false} | ratio: {pred_true/len(test_predictions)}\")\n",
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35ed557",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file(num1, num2):\n",
    "    rows1 = get_file_rows(num1)\n",
    "    rows2 = get_file_rows(num2)\n",
    "    return rows1, rows2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56761a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_file(num1, num2):\n",
    "    directory = f\"../{currentFolder}/data{currentFolder.capitalize()}Complete/\"\n",
    "    file_1 = directory + str(num1) + \".txt\"\n",
    "    file = open(directory + str(num1) + \".txt\", \"r\")\n",
    "    print(file.read())\n",
    "    file.close()\n",
    "    \n",
    "    print(\"- - -\")\n",
    "    \n",
    "    file = open(directory + str(num2) + \".txt\", \"r\")\n",
    "    print(file.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showSegment(num1, num2):\n",
    "    directory = f\"../{currentFolder}/TF-IDF/\"\n",
    "    file = open(directory + str(num1) + \".txt\", \"r\")\n",
    "    print(file.read())\n",
    "    file.close()\n",
    "    \n",
    "    print(\"- - -\")\n",
    "    \n",
    "    file = open(directory + str(num2) + \".txt\", \"r\")\n",
    "    print(file.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafc997e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def check(num1, num2):\n",
    "    display_file(num1, num2)\n",
    "    showSegment(num1, num2)\n",
    "    print(get_file_rows(num1))\n",
    "    print(get_file_rows(num2))\n",
    "    \n",
    "currentFolder = \"train\"\n",
    "check(1236, 1194)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
