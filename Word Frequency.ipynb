{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c27261",
   "metadata": {},
   "source": [
    "# 二次過濾斷詞\n",
    "根據分詞結果加入詞頻計算機制，只留下重要的詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3a043fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b76be35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_corpus(fullPath) :\n",
    "    file = open(fullPath, \"r\").readlines()\n",
    "    return file[0].strip(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c78ad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFolder = \"private\"  # 指定資料集資料夾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816e362c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "# all file in directory\n",
    "mypath = f\"{currentFolder}/ArticleSegment\"\n",
    "files = listdir(mypath)\n",
    "\n",
    "fileList = []  # for index record\n",
    "corpus = []\n",
    "\n",
    "for f in files:\n",
    "    fullpath = join(mypath, f)\n",
    "    if isfile(fullpath):\n",
    "        if(\".txt\" not in fullpath):\n",
    "                continue\n",
    "        fileNum = f.split(\".\")[0]\n",
    "        fileList.append(fileNum)\n",
    "        corpus.append(add_corpus(fullpath))\n",
    "        \n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8af84b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Words: 5840\n"
     ]
    }
   ],
   "source": [
    "print(\"All Words:\", len(wordcount))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74674cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 106)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordcount[\"葉稻熱病\"], wordcount[\"果園\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9d8cc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('防治', 2186), ('發生', 1122), ('藥劑', 1002), ('水稻', 883), ('農友', 737), ('施藥', 618), ('農業', 580), ('危害', 502), ('改良場', 469), ('施用', 448), ('', 420), ('病害', 403), ('籲請', 393), ('田間', 392), ('葉片', 381), ('地區', 365), ('減少', 339), ('密度', 326), ('果實', 323), ('影響', 319), ('感染', 313), ('蔓延', 311), ('病斑', 297), ('稻熱病', 295), ('工作', 281), ('葉稻熱病', 275), ('植株', 263), ('成蟲', 261), ('發現', 252), ('初期', 247), ('發病', 243), ('農民', 241), ('採收期', 234), ('防檢局', 232), ('品質', 213), ('植物保護', 210), ('參考', 209), ('降低', 204), ('幼蟲', 204), ('方法', 204), ('病蟲害', 195), ('病原菌', 191), ('害蟲', 191), ('手冊', 188), ('氮肥', 187), ('作物', 186), ('套袋', 185), ('確保', 184), ('產量', 184), ('稀釋', 178), ('臺南', 178), ('抽穗', 176), ('環境', 173), ('選用', 172), ('預防', 171), ('傳播', 171), ('改場', 166), ('受害', 164), ('稻株', 163), ('推薦', 163), ('香蕉', 156), ('氣候', 156), ('為害', 152), ('栽培', 151), ('時期', 147), ('農藥', 146), ('幼果', 143), ('噴施', 143), ('蕉株', 136), ('高雄', 135), ('關心', 133), ('田邊', 132), ('好幫手', 131), ('颱風', 130), ('產卵', 129), ('白葉枯病', 129), ('監測', 125), ('適合', 125), ('防範', 124), ('噴藥', 122), ('用藥', 121), ('花薊馬', 120), ('生長', 120), ('呼籲', 120), ('稻田', 118), ('損失', 118), ('做好', 117), ('被害', 117), ('侵入', 116), ('穗稻熱病', 116), ('雨水', 115), ('種植', 115), ('葉鞘', 114), ('罹病', 114), ('疫情', 113), ('增加', 112), ('一種', 112), ('管理', 109), ('薊馬', 107), ('果園', 106)]\n"
     ]
    }
   ],
   "source": [
    "print(wordcount.most_common(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1d3eb0",
   "metadata": {},
   "source": [
    "### 先載入關鍵字字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "befaa782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n"
     ]
    }
   ],
   "source": [
    "crops, pests, chems = [], [], []\n",
    "\n",
    "def load_dict(name):\n",
    "    file = open(f\"{name}_dict.txt\", \"r\")\n",
    "    content = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "    items = []\n",
    "    for row in content:\n",
    "        item = row.strip(\"\\n\").split(\" \")[0]\n",
    "        items.append(item)\n",
    "        \n",
    "    return items\n",
    "\n",
    "# 載入關鍵字字典以免誤刪關鍵字\n",
    "crops = load_dict(\"crop\")\n",
    "pests = load_dict(\"pest\")\n",
    "chems = load_dict(\"chem\")\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e07188",
   "metadata": {},
   "outputs": [],
   "source": [
    "currentFolder = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "479b818f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('防治', 2186), ('發生', 1122), ('藥劑', 1002), ('水稻', 883), ('農友', 737), ('施藥', 618), ('農業', 580), ('危害', 502), ('改良場', 469), ('施用', 448), ('', 420), ('病害', 403), ('籲請', 393), ('田間', 392), ('葉片', 381), ('地區', 365), ('減少', 339), ('密度', 326), ('果實', 323), ('影響', 319), ('感染', 313), ('蔓延', 311), ('病斑', 297), ('稻熱病', 295), ('工作', 281), ('葉稻熱病', 275), ('植株', 263), ('成蟲', 261), ('發現', 252), ('初期', 247), ('發病', 243), ('農民', 241), ('採收期', 234), ('防檢局', 232), ('品質', 213), ('植物保護', 210), ('參考', 209), ('降低', 204), ('幼蟲', 204), ('方法', 204), ('病蟲害', 195), ('病原菌', 191), ('害蟲', 191), ('手冊', 188), ('氮肥', 187), ('作物', 186), ('套袋', 185), ('確保', 184), ('產量', 184), ('稀釋', 178)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "wordcount = Counter()  # 計詞 counter\n",
    "\n",
    "mypath = f\"{currentFolder}/ArticleSegment\"\n",
    "files = listdir(mypath)\n",
    "\n",
    "for f in files:\n",
    "    fullpath = join(mypath, f)\n",
    "    if isfile(fullpath):\n",
    "        if(\".txt\" not in fullpath):\n",
    "                continue\n",
    "        file = open(fullpath, \"r\").read().strip(\"\\n\").split(\" \")\n",
    "        for word in file:\n",
    "            wordcount[word] += 1\n",
    "            \n",
    "print(wordcount.most_common(50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862de530",
   "metadata": {},
   "source": [
    "### 設定過濾條件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d956d329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index record for frequncy > 560: 6 | frequency < 10: 1113\n"
     ]
    }
   ],
   "source": [
    "most_common_list = wordcount.most_common()\n",
    "index_10, index_560, i = 0, 0, 0\n",
    "\n",
    "for word, count in most_common_list:\n",
    "    if(count < 10):\n",
    "        index_10 = i\n",
    "        break\n",
    "    elif(count >= 560):\n",
    "        index_560 = i\n",
    "    \n",
    "    i += 1\n",
    "print(\"Index record for frequncy > 560:\", index_560, \"| frequency < 10:\", index_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e787d73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "less than 10: 4726\n",
      "more than 560: 6\n"
     ]
    }
   ],
   "source": [
    "boundary = len(wordcount) - index_10\n",
    "\n",
    "less_than_10 = most_common_list[:-boundary:-1]\n",
    "print(\"frequency less than 10:\", len(less_than_10))\n",
    "\n",
    "more_than_560 = most_common_list[:index_560]\n",
    "print(\"frequency more than 560:\", len(more_than_560))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d80677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('養份', 9),\n",
       " ('地方', 9),\n",
       " ('因素', 9),\n",
       " ('一般而言', 9),\n",
       " ('上應', 9),\n",
       " ('葉色', 9),\n",
       " ('中心', 9),\n",
       " ('下垂', 9),\n",
       " ('標準', 9)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_than_10[:-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41b9a8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4118 ['全區', '點狀', '緣會', '上會', '及於', '懈怠', '源於', '故易', '種植者', '虛弱']\n"
     ]
    }
   ],
   "source": [
    "additional_stop_words = [] # new stopwords list\n",
    "\n",
    "# less than 10\n",
    "for word, count in less_than_10:\n",
    "    if(word not in crops and word not in pests and word not in chems):\n",
    "        additional_stop_words.append(word)\n",
    "\n",
    "# more than 560\n",
    "for word, count in more_than_560:\n",
    "    if(word not in crops and word not in pests and word not in chems):\n",
    "        additional_stop_words.append(word)\n",
    "        \n",
    "print(len(additional_stop_words), additional_stop_words[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5fbdf2",
   "metadata": {},
   "source": [
    "### 把分詞的結果再簡化\n",
    "去掉字頻小於 10 及大於 560 的字詞，並存入另一個 TF-IDF 資料夾內"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "437bf046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 | 100 | 150 | 200 | 250 | 300 | 350 | 400 | \n",
      "-\n"
     ]
    }
   ],
   "source": [
    "mypath = f\"{currentFolder}/ArticleSegment\"\n",
    "files = listdir(mypath)\n",
    "\n",
    "count = 0\n",
    "for f in files:\n",
    "    fullpath = join(mypath, f)\n",
    "    if isfile(fullpath):\n",
    "        if(\".txt\" not in fullpath):\n",
    "                continue\n",
    "\n",
    "        num = f.split(\".\")[0]\n",
    "        file = open(fullpath, \"r\")\n",
    "        content = file.readlines()[0].strip(\"\\n\").split(\" \")\n",
    "        file.close()\n",
    "        \n",
    "        file = open(f\"{currentFolder}/TF-IDF/{num}.txt\", \"w\")\n",
    "        for item in content:\n",
    "            if(item not in additional_stop_words):\n",
    "                file.write(item + \" \")\n",
    "        file.close()\n",
    "        count += 1\n",
    "        if(count % 50 == 0):\n",
    "            print(count, end=\" | \")\n",
    "print(\"\\n-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b6a26faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀入原檔並將詞頻統計結果過濾掉\n",
    "def filterTFIDF(num):\n",
    "    file = open(f\"{currentFolder}/ArticleSegment/{num}.txt\", \"r\")\n",
    "    content = file.read()\n",
    "    file.close()\n",
    "    row = content.strip(\"\\n\").strip(\" \").split(\" \")\n",
    "    fileIndex = fileList.index(num)\n",
    "    count = 0\n",
    "    texts, text = [], \"\"\n",
    "    for item in row:\n",
    "        try:\n",
    "            index = word.index(item)\n",
    "        except:\n",
    "            continue\n",
    "        wordWeight = weight[fileIndex][index]\n",
    "        if(wordWeight >= 0.1 and item not in texts):\n",
    "            texts.append(item)\n",
    "            \n",
    "    for item in texts:\n",
    "        text += (item + \" \")\n",
    "    \n",
    "    file = open(f\"train/TF-IDF/{num}.txt\", \"w\")\n",
    "    file.write(text + \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef8d19a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "['__' '一併' '一個月' '一公頃' '一塊' '一大' '一層' '一帶' '一張' '一期稻作']\n",
      "(420, 5837)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hsiaoping.zhang/tensorflow_macos_venv/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, isdir, join\n",
    "\n",
    "vectorizer = CountVectorizer()    \n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "word = vectorizer.get_feature_names() #所有文本的關鍵字\n",
    "weight = tfidf.toarray()              #對應的tfidf矩陣\n",
    "\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b839d341",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    # full path of the file\n",
    "    fullpath = join(mypath, f)\n",
    "    if isfile(fullpath):\n",
    "        if(\".txt\" not in fullpath):\n",
    "                continue\n",
    "        fileNum = f.split(\".\")[0]\n",
    "        filterTFIDF(fileNum)\n",
    "        \n",
    "print(\"finish\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
